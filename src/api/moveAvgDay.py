import os
import sys
import requests
import pandas as pd
import time
import math
from datetime import datetime, timedelta

# **--- 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (ìƒëŒ€ ê²½ë¡œ ì„í¬íŠ¸ ë¬¸ì œ í•´ê²°) ---**
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.append(project_root)

# ìƒëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
# NOTE: country_loaderì˜ í•¨ìˆ˜ëª…ì´ get_target_currenciesë¡œ ìˆ˜ì •ë˜ì—ˆë‹¤ê³  ê°€ì •
from src.api.api_loader import load_api_key, SERVICE_CODE, BASE_URL
from src.api.country_loader import get_target_currencies 

# --- 1. ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ ---
DAYS_TO_FETCH = 10
DB_DIR = os.path.join(os.path.dirname(__file__), 'database') 
DB_FILE_PREFIX = 'exchange_data_'
MIN_PERIODS = 10 

# --- 2. DB ë° ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜ (ë³µì›ëœ ì´ì „ í•¨ìˆ˜ë“¤) ---

def setup_database(currency_code):
    """DB í´ë”ë¥¼ ìƒì„±í•˜ê³  íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    os.makedirs(DB_DIR, exist_ok=True)
    return os.path.join(DB_DIR, f"{DB_FILE_PREFIX}{currency_code}.csv")

def load_db_data(file_path):
    """ê¸°ì¡´ DB ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. íŒŒì¼ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if os.path.exists(file_path):
        try:
            df = pd.read_csv(file_path, index_col=0, parse_dates=['ë‚ ì§œ'])
            df['ë‚ ì§œ'] = df['ë‚ ì§œ'].dt.strftime('%Y%m%d') 
            df = df.sort_values(by='ë‚ ì§œ', ascending=False)
            return df
        except Exception as e:
            print(f"âš ï¸ {os.path.basename(file_path)} ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}. ìƒˆ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            return pd.DataFrame()
    return pd.DataFrame()

def save_db_data(df, file_path):
    """ë°ì´í„°í”„ë ˆì„ì„ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    if not df.empty:
        df = df.drop_duplicates(subset=['ë‚ ì§œ'], keep='first')
        df = df.sort_values(by='ë‚ ì§œ', ascending=True)
        # ì €ì¥ ì „ 'ë‚ ì§œ'ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (load_db_dataì™€ ì¼ê´€ì„±ì„ ìœ„í•´)
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ']).dt.strftime('%Y%m%d')
        df.to_csv(file_path, index=True, encoding='utf-8')
        print(f"âœ… DB ì €ì¥ ì™„ë£Œ: {os.path.basename(file_path)}, ì´ {len(df)}ì¼ì¹˜ ë°ì´í„°.")
    else:
        print(f"âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ì–´ {os.path.basename(file_path)}ì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --- 3. ìµœì í™”ëœ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ë³µì›ëœ ì´ì „ í•¨ìˆ˜) ---
# NOTE: BASE_URL, SERVICE_CODE ìƒìˆ˜ëŠ” api_loaderì—ì„œ ì„í¬íŠ¸ë˜ì–´ ì „ì—­ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•¨
def fetch_optimized_data(api_key, currency_code, existing_dates, days_needed):
    """ê¸°ì¡´ DB ë°ì´í„°ì— ì—†ëŠ”, í•„ìš”í•œ ë‚ ì§œì˜ ë°ì´í„°ë§Œ API í˜¸ì¶œë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    new_data = []
    fetched_count = 0
    MAX_ITERATIONS = days_needed * 2 + 7 
    
    # BASE_URLê³¼ SERVICE_CODEëŠ” ìƒìœ„ ëª¨ë“ˆì—ì„œ ì„í¬íŠ¸ëœ ì „ì—­ ìƒìˆ˜ì…ë‹ˆë‹¤.

    print(f"ğŸ” [{currency_code}] ì‹ ê·œ ë°ì´í„° í™•ë³´ ì‹œì‘ (í•„ìš”í•œ ì˜ì—…ì¼ ìˆ˜: {days_needed})")

    for i in range(1, MAX_ITERATIONS + 1):
        search_date = (datetime.now() - timedelta(days=i)).strftime("%Y%m%d")
        
        if fetched_count >= days_needed: break
        if search_date in existing_dates: continue

        params = {"authkey": api_key, "searchdate": search_date, "data": SERVICE_CODE}
        
        try:
            response = requests.get(BASE_URL, params=params, timeout=10)
            response.raise_for_status() 
            day_data = response.json()

            if day_data and day_data[0].get('result') == 4:
                print("âŒ API ì œí•œ íšŸìˆ˜ ë§ˆê°.")
                break 

            if day_data and not day_data[0].get('result') == 4:
                for item in day_data:
                    cur_unit = item.get('cur_unit')
                    deal_bas_r_str = item.get('deal_bas_r')

                    if cur_unit == currency_code and deal_bas_r_str:
                        numeric_rate = float(deal_bas_r_str.replace(',', ''))
                        new_data.append({'ë‚ ì§œ': search_date, 'í†µí™”ì½”ë“œ': cur_unit, 'í˜„ì¬í™˜ìœ¨': numeric_rate})
                        fetched_count += 1
                        print(f" Â > [{search_date}] ì‹ ê·œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ. (ì¶”ê°€ í™•ë³´: {fetched_count}/{days_needed}ì¼)")
                        break 
        
        except requests.exceptions.RequestException as e:
            print(f"âŒ [{search_date}] API ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ: {e}. ë°˜ë³µ ì¤‘ë‹¨.")
            break 
            
        time.sleep(0.1) 

    return pd.DataFrame(new_data)


# --- 4. ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ (ì™¸ë¶€ ì°¸ì¡°ìš©) ---

def get_50day_ma_data(api_key):
    """
    í™˜ìœ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ë° ê°±ì‹ í•˜ê³ , 50ì¼ ì´ë™í‰ê· (MA)ì„ ê³„ì‚°í•œ DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    Rê°’ ê³„ì‚° ë¡œì§ì€ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    
    TARGET_CURRENCIES = get_target_currencies() # í†µí™” ì½”ë“œ ëª©ë¡ ë¡œë“œ
    all_ma_results = []
    
    for currency_code in TARGET_CURRENCIES:
        file_path = setup_database(currency_code)
        existing_df = load_db_data(file_path) # ì´ì „ ë°ì´í„° ë¡œë“œ (ë¬¸ìì—´ 'ë‚ ì§œ')
        
        existing_dates = set(existing_df['ë‚ ì§œ'].unique()) if not existing_df.empty else set()
        current_data_count = len(existing_df)
        needed_days = DAYS_TO_FETCH - current_data_count
        
        updated_df = existing_df.copy()

        # 1. ë°ì´í„° ìˆ˜ì§‘ ë° ê°±ì‹  (ìµœì í™”)
        if needed_days > 0:
            new_df = fetch_optimized_data(api_key, currency_code, existing_dates, needed_days)
            updated_df = pd.concat([existing_df, new_df], ignore_index=True)
        else:
            print(f"âœ… [{currency_code}] DBì— ì¶©ë¶„í•œ ë°ì´í„°({current_data_count}ì¼) ì¡´ì¬. API í˜¸ì¶œ ê±´ë„ˆëœƒë‹ˆë‹¤.")

        
        # 2. ì´ë™í‰ê·  ê³„ì‚°
        if len(updated_df) >= MIN_PERIODS:
            
            # MA ê³„ì‚°ì„ ìœ„í•´ ë‚ ì§œë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜í•˜ê³  ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            updated_df['ë‚ ì§œ'] = pd.to_datetime(updated_df['ë‚ ì§œ'])
            updated_df = updated_df.sort_values(by='ë‚ ì§œ', ascending=True).reset_index(drop=True)
            
            # 50ì¼ MA ê³„ì‚°
            updated_df['50ì¼_MA'] = updated_df['í˜„ì¬í™˜ìœ¨'].rolling(window=DAYS_TO_FETCH, min_periods=MIN_PERIODS).mean()
            
            # 3. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (ë‹¤ìŒ ì‹¤í–‰ì„ ìœ„í•´ ê°±ì‹ )
            # (save_db_data ë‚´ë¶€ì—ì„œ ë‚ ì§œë¥¼ ë‹¤ì‹œ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥)
            save_db_data(updated_df, file_path)

            # 4. ë°˜í™˜ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ (Rê°’ ê³„ì‚°ì— í•„ìš”í•œ ìµœì¢… ë°ì´í„°)
            latest_ma_data = updated_df.iloc[-1]
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ë‚ ì§œëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜)
            all_ma_results.append({
                'í†µí™”ì½”ë“œ': currency_code,
                'ë‚ ì§œ': latest_ma_data['ë‚ ì§œ'].strftime('%Y%m%d'),
                'í˜„ì¬í™˜ìœ¨': latest_ma_data['í˜„ì¬í™˜ìœ¨'],
                '50ì¼_MA': latest_ma_data['50ì¼_MA']
            })

        else:
            print(f"âš ï¸ [{currency_code}] ë°ì´í„°ê°€ ìµœì†Œ {MIN_PERIODS}ì¼ ë¯¸ë§Œì´ë¼ ì´ë™í‰ê·  ê³„ì‚° ë¶ˆê°€. ({len(updated_df)}ì¼)")

    return pd.DataFrame(all_ma_results)

if __name__ == "__main__":
    API_KEY, _, _ = load_api_key()
    
    print("50ì¼ ì´ë™í‰ê·  ë°ì´í„° ìˆ˜ì§‘ ë° ê°±ì‹ ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    result_df = get_50day_ma_data(API_KEY)
    
    if not result_df.empty:
        print("\n[ìµœì¢… 50ì¼ ì´ë™í‰ê·  ë°ì´í„° (Rê°’ ê³„ì‚°ìš©)]")
        # Rê°’ì€ ê³„ì‚°í•˜ì§€ ì•Šê³ , í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶œë ¥
        print(result_df[['í†µí™”ì½”ë“œ', 'ë‚ ì§œ', 'í˜„ì¬í™˜ìœ¨', '50ì¼_MA']].to_markdown(index=False, floatfmt=".2f"))
    else:
        print("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")